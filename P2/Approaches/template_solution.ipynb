{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This serves as a template which will guide you through the implementation of this task.  It is advised\n",
    "# to first read the whole template and get a sense of the overall structure of the code\n",
    "# First, we import necessary libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, RBF, Matern, RationalQuadratic, ExpSineSquared\n",
    "from sklearn.kernel_approximation import PolynomialCountSketch\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    \"\"\"\n",
    "    This function loads the training and test data, preprocesses it, removes the NaN values and interpolates the missing\n",
    "    data using imputation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with features\n",
    "    y_train: array of floats, training output with labels\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with features\n",
    "    \"\"\"\n",
    "    # Load training data\n",
    "    train_df = pd.read_csv(\"/home/otps3141/Documents/Git Hub/IML-2023/P2/train.csv\")\n",
    "\n",
    "\n",
    "\n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(\"/home/otps3141/Documents/Git Hub/IML-2023/P2/test.csv\")\n",
    "\n",
    "\n",
    "\n",
    "    # Perform data preprocessing, imputation and extract X_train, y_train and X_test using mean values\n",
    "\n",
    "    # Use interpolation for missing values. Interpolate cannot handle missing starting or end values. So fill these up with mean()\n",
    "\n",
    "    # Why does this not work with RBF?\n",
    "\n",
    "    ### Training set\n",
    "\n",
    "    new_train_df = train_df.interpolate(method=\"akima\")\n",
    "    new_train_df = new_train_df.fillna(train_df.mean())\n",
    "\n",
    "\n",
    "    # Encode season data\n",
    "\n",
    "    binary_version_seasons = pd.get_dummies(new_train_df['season'])\n",
    "    new_train_df = new_train_df.drop(columns=['season']).join(binary_version_seasons)\n",
    "\n",
    "    ### Test set\n",
    "\n",
    "    new_test_df = test_df.interpolate(method=\"akima\")\n",
    "    new_test_df = new_test_df.fillna(new_test_df.mean())\n",
    "\n",
    "    # Encode season data\n",
    "\n",
    "    new_test_df = new_test_df.drop(columns=['season']).join(binary_version_seasons)\n",
    "\n",
    "    ###\n",
    "\n",
    "    seasons = train_df['season'].unique().tolist()\n",
    "    seasonal_data_index = pd.DataFrame(test_df['season'])\n",
    "\n",
    "    season_X_train = {}\n",
    "    season_y_train = {}\n",
    "    season_X_test = {'seasonal_data': seasonal_data_index}\n",
    "\n",
    "    for season in seasons:\n",
    "\n",
    "        season_X_train[f'{season}'] = new_train_df[new_train_df[f'{season}'] == 1].drop(columns=[\"price_CHF\"])\n",
    "        season_y_train[f'{season}'] = new_train_df[new_train_df[f'{season}'] == 1]['price_CHF']\n",
    "        season_X_test[f'{season}'] = new_test_df[new_test_df[f'{season}'] == 1]\n",
    "\n",
    "    print(season_X_test)\n",
    "\n",
    "    # assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (\n",
    "    #             X_test.shape[0] == 100), \"Invalid data shape\"\n",
    "\n",
    "    return season_X_train, season_y_train, season_X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_R2(y_pred, y):\n",
    "\n",
    "    R2 = r2_score(y, y_pred)\n",
    "\n",
    "    assert np.isscalar(R2)\n",
    "    return R2\n",
    "\n",
    "\n",
    "def calculate_RMSE(y_pred, y):\n",
    "    \"\"\"This function takes test data points (X and y), and computes the empirical RMSE of\n",
    "    predicting y from X using a linear model with weights w.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred: array of floats\n",
    "    y: array of floats, dim = (15,), input labels\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    RMSE: float: dim = 1, RMSE value\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine mean squared error\n",
    "    RMSE = mean_squared_error(y, y_pred) ** 0.5\n",
    "\n",
    "    assert np.isscalar(RMSE)\n",
    "    return RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling_and_prediction(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    This function defines the model, fits training data and then does the prediction with the test data \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with 10 features\n",
    "    y_train: array of floats, training output\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with 10 features\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    y_test: array of floats: dim = (100,), predictions on test set\n",
    "    \"\"\"\n",
    "\n",
    "    # y_pred=np.zeros(X_test.shape[0])\n",
    "    y_pred = np.zeros(X_test['seasonal_data'].shape[0])\n",
    "    #TODO: Define the model and fit it using training data. Then, use test data to make predictions\n",
    "\n",
    "    # Define n_fold cross validation\n",
    "    kf = KFold(10)\n",
    "\n",
    "    # Define error\n",
    "    error_model = 'R2'\n",
    "\n",
    "    # Define model\n",
    "    model = GaussianProcessRegressor(kernel=RBF())\n",
    "\n",
    "    # Define seasons\n",
    "    seasonal_data_indexes = X_test['seasonal_data']\n",
    "    print(seasonal_data_indexes)\n",
    "    seasons = seasonal_data_indexes['season'].unique().tolist()\n",
    "\n",
    "\n",
    "    # Define storage for y prediction\n",
    "    y_pred_dict = {}\n",
    "\n",
    "    for season in seasons:\n",
    "        X_test_season = X_test[season].drop(columns=seasons).to_numpy()\n",
    "        X_train_season = X_train[season].drop(columns=seasons).to_numpy()\n",
    "        y_train_season = y_train[season].to_numpy()\n",
    "\n",
    "        y_pred_dict[season] = _fit_kfold(kf_splitter=kf, X_test=X_test_season, X_train=X_train_season,\n",
    "                                    y_train=y_train_season, error_method=error_model, model=model)\n",
    "\n",
    "        indices = seasonal_data_indexes.index[seasonal_data_indexes['season'] == season].to_numpy()\n",
    "        y_pred[indices] = y_pred_dict[season]\n",
    "\n",
    "\n",
    "    assert y_pred.shape == (100,), \"Invalid data shape\"\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def modeling_and_prediction(X_train, y_train, X_test):\n",
    "#     \"\"\"\n",
    "#     This function defines the model, fits training data and then does the prediction with the test data\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     X_train: matrix of floats, training input with 10 features\n",
    "#     y_train: array of floats, training output\n",
    "#     X_test: matrix of floats: dim = (100, ?), test input with 10 features\n",
    "\n",
    "#     Returns\n",
    "#     ----------\n",
    "#     y_test: array of floats: dim = (100,), predictions on test set\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Create storage array for predicted y values\n",
    "#     y_pred1 = np.zeros(X_test.shape[0])\n",
    "\n",
    "#     # Leave out seasons data\n",
    "#     # X_train = X_train[:, 1:]\n",
    "\n",
    "#     # Define final test data\n",
    "#     X_test1 = X_test\n",
    "\n",
    "#     X_train = np.array(X_train)\n",
    "#     y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "#     # Storage array for RMSE values\n",
    "#     RMSE_mat = np.zeros(9)\n",
    "#     R2_mat = np.zeros(9)\n",
    "\n",
    "#     # Define n_fold cross validation\n",
    "#     kf = KFold(9)\n",
    "#     mat_i = 0\n",
    "\n",
    "#     # Storage for all n_fold models\n",
    "#     models = []\n",
    "\n",
    "#     # Perform Cross validation\n",
    "#     for train_index, test_index in kf.split(X_train):\n",
    "#         X_train_folds = X_train[train_index]\n",
    "#         y_train_folds = y_train[train_index]\n",
    "\n",
    "#         gpr = GaussianProcessRegressor(kernel=DotProduct())\n",
    "#         gpr.fit(X_train_folds, y_train_folds)\n",
    "\n",
    "#         X_test = X_train[test_index]\n",
    "#         y_test = y_train[test_index]\n",
    "\n",
    "#         y_pred, sigma = gpr.predict(X_test, return_std=True)\n",
    "\n",
    "#         # print(sigma)\n",
    "\n",
    "#         models.append(gpr)\n",
    "\n",
    "#         RMSE_mat[mat_i] = calculate_RMSE(y_pred, y_test)\n",
    "#         R2_mat[mat_i] = calculate_R2(y_pred, y_test)\n",
    "\n",
    "#         mat_i = mat_i + 1\n",
    "\n",
    "#     # print(RMSE_mat)\n",
    "#     # print(R2_mat)\n",
    "\n",
    "#     # Determine best model\n",
    "#     best_index_RMSE = np.argmin(RMSE_mat)\n",
    "#     best_index_R2 = np.argmin(R2_mat)\n",
    "\n",
    "#     final_gpr_RMSE = models[best_index_RMSE]\n",
    "#     final_gpr_R2 = models[best_index_R2]\n",
    "\n",
    "#     # y_pred = final_gpr_RMSE.predict(X_test1[:, 1:])\n",
    "#     y_pred = final_gpr_R2.predict(X_test1[:, :])\n",
    "\n",
    "\n",
    "#     # print(gpr.score(X_train[:,1:], y_train))\n",
    "\n",
    "#     '''\n",
    "#     ps = PolynomialCountSketch(degree=3, random_state=1)\n",
    "#     X_features = ps.fit_transform(X)\n",
    "#     #print(np.exp(X_train[5,1]))\n",
    "#     '''\n",
    "#     # plt.plot(np.exp(X_train[:,1]),np.exp(y_train),'.')\n",
    "\n",
    "#     assert y_pred.shape == (100,), \"Invalid data shape\"\n",
    "#     return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_kfold(kf_splitter, X_test, X_train, y_train, model, error_method):\n",
    "    \"\"\"\"\n",
    "    Helper function to compute the KFolds and keep the rest of the modeling function cleaner.\n",
    "    The model is the machine learning model that fits the data.\n",
    "    \"\"\"\n",
    "    # Storage for errors\n",
    "    error_matrix = np.zeros(kf_splitter.get_n_splits())\n",
    "\n",
    "    # Storage for all n_fold models\n",
    "    models = []\n",
    "\n",
    "    # Perform Cross validation\n",
    "    for i, (train_index, test_index) in enumerate(kf_splitter.split(X_train)):\n",
    "        X_train_folds = X_train[train_index]\n",
    "        y_train_folds = y_train[train_index]\n",
    "\n",
    "        X_test_folds = X_train[test_index]\n",
    "        y_test_folds = y_train[test_index]\n",
    "\n",
    "        # The model is refitted every time.\n",
    "        model.fit(X_train_folds, y_train_folds)\n",
    "        y_pred_folds, sigma = model.predict(X_test_folds, return_std=True)\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "        if error_method == 'RMSE':\n",
    "            error_matrix[i] = calculate_RMSE(y_pred_folds, y_test_folds)\n",
    "\n",
    "        elif error_method == 'R2':\n",
    "            error_matrix[i] = calculate_R2(y_pred_folds, y_test_folds)\n",
    "\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "\n",
    "    best_index = np.argmin(error_matrix)\n",
    "    best_fit = models[best_index]\n",
    "\n",
    "    y_pred = best_fit.predict(X_test)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_574927/2379935306.py:33: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  new_train_df = new_train_df.fillna(train_df.mean())\n",
      "/tmp/ipykernel_574927/2379935306.py:44: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  new_test_df = new_test_df.fillna(new_test_df.mean())\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seasonal_data':     season\n",
      "0   spring\n",
      "1   summer\n",
      "2   autumn\n",
      "3   winter\n",
      "4   spring\n",
      "..     ...\n",
      "95  winter\n",
      "96  spring\n",
      "97  summer\n",
      "98  autumn\n",
      "99  winter\n",
      "\n",
      "[100 rows x 1 columns], 'spring':     price_AUS  price_CZE  price_GER  price_ESP  price_FRA  price_UK  \\\n",
      "0   -1.330600   0.472985   0.707957  -4.009095  -1.136441 -0.596703   \n",
      "4   -1.073283   0.269644   0.771367  -3.245495  -1.362051 -0.717914   \n",
      "8   -1.022435   0.223203   0.354883  -3.463741  -2.080806 -1.123629   \n",
      "12  -0.988912   0.148753  -0.250353  -3.556490  -2.708207 -1.764621   \n",
      "16  -0.010806   0.867905   0.203440  -3.864960  -2.084972 -2.618636   \n",
      "20   1.104458   1.578264   0.759595  -5.113536  -1.886305 -3.632169   \n",
      "24  -0.266613   0.312605   0.082486  -5.453085  -2.766415 -3.297773   \n",
      "28  -1.880496  -1.582728  -1.416744  -3.871082  -3.987534 -2.222841   \n",
      "32  -1.989714  -1.962855  -2.057360  -3.329145  -4.002571 -1.793212   \n",
      "36  -1.466735  -1.747831  -2.122145  -3.650584  -4.099147 -1.813720   \n",
      "40  -1.326802  -1.460875  -1.842274  -3.997681  -4.013873 -1.578960   \n",
      "44  -1.458109  -1.513460  -1.917169  -3.962041  -4.059849 -1.678168   \n",
      "48  -2.029117  -1.931842  -2.010958  -3.422930  -4.019209 -1.813673   \n",
      "52  -2.125982  -2.064880  -1.812033  -3.440542  -4.119550 -1.981402   \n",
      "56  -1.925877  -1.638917  -1.504031  -3.756049  -3.982032 -2.126419   \n",
      "60  -1.190726  -1.008590  -0.982222  -4.600879  -3.568725 -2.696878   \n",
      "64  -0.906180  -0.719191  -0.627230  -4.998930  -3.341663 -2.941306   \n",
      "68  -0.699205  -0.277778  -0.402146  -5.134934  -3.298190 -2.997012   \n",
      "72  -0.910632  -0.629831  -0.591806  -4.861055  -3.158594 -2.770989   \n",
      "76  -1.398777  -1.047298  -1.032372  -4.415810  -3.488996 -2.628918   \n",
      "80  -1.916854  -1.562734  -1.425074  -3.824087  -3.858535 -2.375201   \n",
      "84  -2.241943  -1.811676  -1.731659  -3.424183  -4.093356 -2.156429   \n",
      "88  -2.238849  -2.135457  -1.728957  -3.460139  -4.045882 -2.117879   \n",
      "92  -2.024489  -1.945340  -1.640917  -3.432540  -3.924958 -2.108671   \n",
      "96  -1.817763  -1.411416  -1.231994  -3.995247  -3.760752 -2.443732   \n",
      "\n",
      "    price_ITA  price_POL  price_SVK  autumn  spring  summer  winter  \n",
      "0   -3.304914   3.298693   1.921886       0       1       0       0  \n",
      "4   -1.341538   3.205007   2.101199       0       1       0       0  \n",
      "8   -1.755596   3.064055   2.342439       0       1       0       0  \n",
      "12  -2.263187   2.728035   2.294461       0       1       0       0  \n",
      "16  -2.016913   2.019755   1.883842       0       1       0       0  \n",
      "20  -1.544725   0.897763   0.879192       0       1       0       0  \n",
      "24  -2.646927  -1.141192  -1.510016       0       1       0       0  \n",
      "28  -3.788189  -2.127034  -3.058460       0       1       0       0  \n",
      "32  -3.805182  -2.536077  -3.204143       0       1       0       0  \n",
      "36  -3.617509  -2.376767  -2.794411       0       1       0       0  \n",
      "40  -3.463019  -2.323052  -2.806061       0       1       0       0  \n",
      "44  -3.555772  -2.586486  -2.844691       0       1       0       0  \n",
      "48  -3.709261  -2.583305  -3.160914       0       1       0       0  \n",
      "52  -4.215933  -2.647170  -3.246055       0       1       0       0  \n",
      "56  -3.996307  -2.292932  -2.975486       0       1       0       0  \n",
      "60  -3.609687  -1.997350  -2.567268       0       1       0       0  \n",
      "64  -3.459639  -1.402583  -2.264542       0       1       0       0  \n",
      "68  -3.269024  -1.517095  -2.112544       0       1       0       0  \n",
      "72  -3.508675  -1.691142  -2.447547       0       1       0       0  \n",
      "76  -3.869471  -1.917522  -2.888745       0       1       0       0  \n",
      "80  -3.954192  -2.064235  -3.034458       0       1       0       0  \n",
      "84  -4.119581  -2.261067  -3.144566       0       1       0       0  \n",
      "88  -3.931172  -2.747374  -3.250224       0       1       0       0  \n",
      "92  -4.119586  -2.461299  -3.341060       0       1       0       0  \n",
      "96  -3.903510  -2.269992  -3.007311       0       1       0       0  , 'summer':     price_AUS  price_CZE  price_GER  price_ESP  price_FRA  price_UK  \\\n",
      "1   -1.184837   0.358019   0.741609  -3.199028  -1.069695 -0.579515   \n",
      "5   -1.052378   0.282322   0.701187  -3.290904  -1.616790 -0.715345   \n",
      "9   -1.142665   0.170048   0.092055  -3.342628  -2.346018 -1.293035   \n",
      "13  -0.830697   0.247614  -0.447258  -3.590638  -2.929378 -1.721985   \n",
      "17   0.091853   1.145791   0.394663  -4.244226  -1.972765 -2.994673   \n",
      "21   1.171766   1.259591   0.566888  -5.359800  -1.971671 -3.770748   \n",
      "25  -0.721433  -0.338533  -0.335734  -5.220247  -3.222722 -3.071133   \n",
      "29  -2.133169  -1.660176  -1.718492  -3.578461  -4.076280 -1.917748   \n",
      "33  -1.958378  -1.906225  -1.925857  -3.402910  -3.933193 -1.686346   \n",
      "37  -1.367546  -1.616513  -1.902253  -3.737842  -3.993378 -1.710568   \n",
      "41  -1.250615  -1.461738  -1.749200  -4.079831  -3.700387 -1.610388   \n",
      "45  -1.531383  -1.649813  -1.859662  -3.902145  -4.094396 -1.803519   \n",
      "49  -2.120839  -2.058320  -2.016838  -3.429621  -4.036399 -1.710688   \n",
      "53  -2.120066  -1.991560  -1.769480  -3.596234  -4.166013 -2.084610   \n",
      "57  -1.548571  -1.370477  -1.344293  -3.934714  -3.629401 -2.234818   \n",
      "61  -1.092925  -0.615735  -0.932683  -4.684529  -3.620276 -2.700964   \n",
      "65  -0.836336  -0.607733  -0.636868  -5.002210  -3.227120 -3.035220   \n",
      "69  -0.796071  -0.492897  -0.366802  -5.114145  -3.272649 -3.023646   \n",
      "73  -1.008902  -0.859169  -0.539618  -4.788927  -3.395936 -2.810722   \n",
      "77  -1.567927  -1.169758  -1.072399  -4.292927  -3.636004 -2.426536   \n",
      "81  -2.037529  -1.712958  -1.543003  -3.616734  -3.831452 -2.293072   \n",
      "85  -2.135588  -1.685666  -1.647496  -3.414668  -4.011601 -2.122030   \n",
      "89  -2.235183  -1.925833  -1.785445  -3.386333  -3.740732 -1.977734   \n",
      "93  -1.953280  -1.874656  -1.565002  -3.553317  -3.908172 -2.131869   \n",
      "97  -1.671272  -1.201048  -1.140538  -4.084448  -3.968988 -2.555133   \n",
      "\n",
      "    price_ITA  price_POL  price_SVK  autumn  spring  summer  winter  \n",
      "1   -1.420091   3.238307   1.972984       0       0       1       0  \n",
      "5   -1.404699   3.154514   2.135336       0       0       1       0  \n",
      "9   -2.070839   3.067167   2.277053       0       0       1       0  \n",
      "13  -2.444701   2.316934   2.135545       0       0       1       0  \n",
      "17  -1.665286   1.902450   1.718711       0       0       1       0  \n",
      "21  -1.591953   0.400137   0.589328       0       0       1       0  \n",
      "25  -3.195199  -1.528077  -2.062926       0       0       1       0  \n",
      "29  -3.899496  -2.321954  -3.255619       0       0       1       0  \n",
      "33  -3.666336  -2.523769  -3.213848       0       0       1       0  \n",
      "37  -3.552061  -2.493790  -2.746885       0       0       1       0  \n",
      "41  -3.446030  -2.266538  -2.821085       0       0       1       0  \n",
      "45  -3.549756  -2.583161  -2.927825       0       0       1       0  \n",
      "49  -3.756298  -2.594593  -3.202881       0       0       1       0  \n",
      "53  -4.262119  -2.534574  -3.218204       0       0       1       0  \n",
      "57  -3.919083  -2.222115  -2.879517       0       0       1       0  \n",
      "61  -3.471481  -1.668077  -2.201543       0       0       1       0  \n",
      "65  -3.492806  -1.380929  -2.207514       0       0       1       0  \n",
      "69  -3.295165  -1.611757  -2.203175       0       0       1       0  \n",
      "73  -3.654204  -1.852145  -2.528469       0       0       1       0  \n",
      "77  -3.963945  -1.846679  -2.868300       0       0       1       0  \n",
      "81  -3.917730  -2.179897  -3.182940       0       0       1       0  \n",
      "85  -4.067702  -2.312992  -3.131665       0       0       1       0  \n",
      "89  -4.016725  -2.431041  -3.218960       0       0       1       0  \n",
      "93  -4.160111  -2.441735  -3.276092       0       0       1       0  \n",
      "97  -4.058773  -2.146487  -2.816678       0       0       1       0  , 'autumn':     price_AUS  price_CZE  price_GER  price_ESP  price_FRA  price_UK  \\\n",
      "2   -1.116459   0.354504   0.780460  -3.338948  -1.053149 -0.586339   \n",
      "6   -1.011294   0.302123   0.631524  -3.304202  -1.814073 -0.843341   \n",
      "10  -1.174969   0.188982  -0.014898  -3.586335  -2.490026 -1.456322   \n",
      "14  -0.718489   0.416842  -0.170009  -3.614262  -2.624043 -2.066631   \n",
      "18   0.413472   1.408803   0.536132  -4.544838  -1.877705 -3.214565   \n",
      "22   0.795195   0.897825   0.375507  -5.527086  -1.992431 -3.666737   \n",
      "26  -1.158848  -0.797374  -0.820947  -4.736472  -3.563699 -2.569234   \n",
      "30  -2.301217  -1.844330  -1.939626  -3.412455  -4.129331 -1.987485   \n",
      "34  -1.653414  -1.836162  -2.006631  -3.481973  -3.919680 -1.626792   \n",
      "38  -1.235567  -1.282759  -1.756516  -3.825542  -3.901086 -1.633312   \n",
      "42  -1.430368  -1.405806  -1.863950  -4.157841  -3.944965 -1.673500   \n",
      "46  -1.514619  -1.848589  -1.938846  -3.924650  -4.007390 -1.703596   \n",
      "50  -2.063706  -1.861402  -2.022301  -3.252994  -4.055516 -1.804816   \n",
      "54  -2.023179  -1.869259  -1.720423  -3.410964  -4.051514 -2.151486   \n",
      "58  -1.433004  -1.418303  -1.076903  -4.159064  -3.628320 -2.391780   \n",
      "62  -0.999652  -0.600322  -0.854572  -4.755883  -3.291336 -2.870830   \n",
      "66  -0.767797  -0.496631  -0.660940  -4.985582  -3.207346 -3.045644   \n",
      "70  -0.915440  -0.590526  -0.392840  -5.081595  -3.221751 -3.014718   \n",
      "74  -1.126041  -0.859471  -0.891490  -4.670002  -3.509790 -2.562860   \n",
      "78  -1.602256  -1.438173  -1.187435  -4.155616  -3.748215 -2.334096   \n",
      "82  -2.138546  -1.711193  -1.658546  -3.451053  -3.798521 -2.001108   \n",
      "86  -2.150318  -1.845036  -1.737686  -3.430664  -4.008119 -1.935269   \n",
      "90  -2.177212  -2.044232  -1.835039  -3.272274  -3.881999 -2.033795   \n",
      "94  -2.134433  -1.790287  -1.446606  -3.689328  -3.840504 -2.186037   \n",
      "98  -1.555702  -1.029762  -0.964712  -4.216490  -3.705548 -2.487751   \n",
      "\n",
      "    price_ITA  price_POL  price_SVK  autumn  spring  summer  winter  \n",
      "2   -1.331542   3.207398   2.020570       1       0       0       0  \n",
      "6   -1.421887   3.180659   2.170232       1       0       0       0  \n",
      "10  -2.131554   2.930935   2.187602       1       0       0       0  \n",
      "14  -2.310890   2.252189   2.011963       1       0       0       0  \n",
      "18  -1.627344   1.470072   1.549530       1       0       0       0  \n",
      "22  -2.010630  -0.094093  -0.111174       1       0       0       0  \n",
      "26  -3.654280  -1.730309  -2.337271       1       0       0       0  \n",
      "30  -4.120031  -2.511145  -3.332705       1       0       0       0  \n",
      "34  -3.836920  -2.658678  -3.184425       1       0       0       0  \n",
      "38  -3.593075  -2.484658  -2.849689       1       0       0       0  \n",
      "42  -3.357397  -2.358626  -2.814284       1       0       0       0  \n",
      "46  -3.561654  -2.577377  -2.927798       1       0       0       0  \n",
      "50  -4.058399  -2.771276  -3.230389       1       0       0       0  \n",
      "54  -4.280068  -2.426380  -3.284734       1       0       0       0  \n",
      "58  -3.852021  -2.148955  -2.658559       1       0       0       0  \n",
      "62  -3.413461  -1.757526  -2.205329       1       0       0       0  \n",
      "66  -3.223816  -1.390012  -2.170823       1       0       0       0  \n",
      "70  -3.424160  -1.380740  -2.284769       1       0       0       0  \n",
      "74  -3.599204  -1.973291  -2.609284       1       0       0       0  \n",
      "78  -3.961140  -2.040937  -2.935736       1       0       0       0  \n",
      "82  -4.030197  -2.281012  -2.969549       1       0       0       0  \n",
      "86  -3.992946  -2.368256  -3.241535       1       0       0       0  \n",
      "90  -4.096333  -2.430334  -3.198704       1       0       0       0  \n",
      "94  -4.113256  -2.518599  -3.075311       1       0       0       0  \n",
      "98  -3.745480  -1.996185  -2.849707       1       0       0       0  , 'winter':     price_AUS  price_CZE  price_GER  price_ESP  price_FRA  price_UK  \\\n",
      "3   -1.090106   0.353066   0.833429  -3.287990  -1.322626 -0.628873   \n",
      "7   -0.968575   0.159716   0.566105  -3.323523  -1.948460 -0.979281   \n",
      "11  -1.060290   0.211954  -0.288732  -3.535783  -2.592385 -1.612508   \n",
      "15  -0.611972   0.619286   0.016203  -3.535496  -2.223558 -2.338519   \n",
      "19   0.790135   1.593645   0.814674  -4.840109  -1.829922 -3.430836   \n",
      "23   0.298883   0.689535   0.389529  -5.556773  -2.547198 -3.491159   \n",
      "27  -1.655067  -1.217764  -1.119792  -4.222027  -3.829395 -2.288085   \n",
      "31  -2.321117  -1.976963  -2.036851  -3.429074  -4.115879 -1.964513   \n",
      "35  -1.551811  -1.822151  -2.214611  -3.564913  -3.990569 -1.613806   \n",
      "39  -1.257323  -1.295492  -1.747226  -3.912536  -3.819060 -1.578123   \n",
      "43  -1.442425  -1.412312  -1.848320  -4.230565  -4.007721 -1.562263   \n",
      "47  -1.834398  -1.811584  -2.006948  -3.855428  -4.004793 -1.834156   \n",
      "51  -2.085581  -1.928399  -1.842604  -3.366722  -4.075718 -1.914661   \n",
      "55  -1.976775  -1.747066  -1.636182  -3.580572  -3.888679 -2.090930   \n",
      "59  -1.316797  -1.157565  -1.003008  -4.465727  -3.535182 -2.762811   \n",
      "63  -0.961187  -0.522537  -0.640274  -4.854143  -3.519802 -2.905812   \n",
      "67  -0.716706  -0.386033  -0.513743  -5.130225  -3.293521 -2.978334   \n",
      "71  -0.916386  -0.653693  -0.484825  -5.023894  -3.176878 -2.897433   \n",
      "75  -1.257512  -0.882835  -0.936684  -4.445342  -3.346593 -2.764555   \n",
      "79  -1.755995  -1.507563  -1.305772  -4.008246  -3.735418 -2.374269   \n",
      "83  -2.209989  -1.686756  -1.770568  -3.510497  -4.174906 -2.228679   \n",
      "87  -2.189685  -1.991825  -1.672559  -3.491931  -4.010947 -2.018650   \n",
      "91  -2.101343  -2.124836  -1.838124  -3.318755  -4.014393 -2.087864   \n",
      "95  -2.030894  -1.621088  -1.332104  -3.838154  -3.791411 -2.319565   \n",
      "99  -1.472852  -0.935032  -0.964712  -4.463277  -3.488559 -2.166592   \n",
      "\n",
      "    price_ITA  price_POL  price_SVK  autumn  spring  summer  winter  \n",
      "3   -1.304240   3.159858   2.064163       0       0       0       1  \n",
      "7   -1.839364   3.202248   2.209548       0       0       0       1  \n",
      "11  -2.264034   2.873675   2.409418       0       0       0       1  \n",
      "15  -2.165986   2.190997   1.967391       0       0       0       1  \n",
      "19  -1.385705   1.479627   1.389497       0       0       0       1  \n",
      "23  -2.496478  -0.622200  -0.816930       0       0       0       1  \n",
      "27  -3.692244  -1.928961  -2.794185       0       0       0       1  \n",
      "31  -4.053506  -2.584031  -3.112621       0       0       0       1  \n",
      "35  -3.650729  -2.519241  -3.095833       0       0       0       1  \n",
      "39  -3.529123  -2.415858  -2.643545       0       0       0       1  \n",
      "43  -3.573637  -2.579597  -2.813028       0       0       0       1  \n",
      "47  -3.626945  -2.576889  -3.045550       0       0       0       1  \n",
      "51  -4.149952  -2.673971  -3.244444       0       0       0       1  \n",
      "55  -4.148876  -2.360969  -3.338251       0       0       0       1  \n",
      "59  -3.747997  -2.073888  -2.606354       0       0       0       1  \n",
      "63  -3.419935  -1.566044  -2.259645       0       0       0       1  \n",
      "67  -3.217156  -1.420579  -1.965196       0       0       0       1  \n",
      "71  -3.362117  -1.539241  -2.366290       0       0       0       1  \n",
      "75  -3.711840  -2.005619  -2.611932       0       0       0       1  \n",
      "79  -4.013601  -2.271975  -2.866934       0       0       0       1  \n",
      "83  -4.109490  -2.262756  -3.058547       0       0       0       1  \n",
      "87  -3.934405  -2.398114  -3.266436       0       0       0       1  \n",
      "91  -4.108842  -2.467623  -3.215515       0       0       0       1  \n",
      "95  -3.991367  -2.134084  -2.880557       0       0       0       1  \n",
      "99  -3.534069  -1.836267  -1.733983       0       0       0       1  }\n",
      "    season\n",
      "0   spring\n",
      "1   summer\n",
      "2   autumn\n",
      "3   winter\n",
      "4   spring\n",
      "..     ...\n",
      "95  winter\n",
      "96  spring\n",
      "97  summer\n",
      "98  autumn\n",
      "99  winter\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results file successfully generated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/otps3141/.local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Data load\n",
    "X_train, y_train, X_test = data_loading()\n",
    "# The function retrieving optimal LR parameters\n",
    "y_pred = modeling_and_prediction(X_train, y_train, X_test)\n",
    "# Save results in the required format\n",
    "\n",
    "dt = pd.DataFrame(y_pred)\n",
    "\n",
    "dt.columns = ['price_CHF']\n",
    "dt.to_csv('/home/otps3141/Documents/Git Hub/IML-2023/P2/results.csv', index=False)\n",
    "print(\"\\nResults file successfully generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
