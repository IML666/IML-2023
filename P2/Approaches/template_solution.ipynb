{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This serves as a template which will guide you through the implementation of this task.  It is advised\n",
    "# to first read the whole template and get a sense of the overall structure of the code\n",
    "# First, we import necessary libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, RBF, Matern, RationalQuadratic, ExpSineSquared\n",
    "from sklearn.kernel_approximation import PolynomialCountSketch\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    \"\"\"\n",
    "    This function loads the training and test data, preprocesses it, removes the NaN values and interpolates the missing\n",
    "    data using imputation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with features\n",
    "    y_train: array of floats, training output with labels\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with features\n",
    "    \"\"\"\n",
    "    # Load training data\n",
    "    train_df = pd.read_csv(\"P2/train.csv\")\n",
    "\n",
    "    # print(\"Training data:\")\n",
    "    # print(\"Shape:\", train_df.shape)\n",
    "    # print(train_df.head(2))\n",
    "    # print('\\n')\n",
    "\n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(\"P2/test.csv\")\n",
    "\n",
    "    # print(\"Test data:\")\n",
    "    # print(test_df.shape)\n",
    "    # print(test_df.head(2))\n",
    "\n",
    "    # # Dummy initialization of the X_train, X_test and y_train\n",
    "    # X_train = np.zeros_like(train_df.drop(['price_CHF'], axis=1))\n",
    "    # y_train = np.zeros_like(train_df['price_CHF'])\n",
    "    # X_test = np.zeros_like(test_df)\n",
    "\n",
    "    # print(train_df)\n",
    "\n",
    "    # Perform data preprocessing, imputation and extract X_train, y_train and X_test using mean values\n",
    "\n",
    "    # Use interpolation for missing values. Interpolate cannot handle missing starting or end values. So fill these up with mean()\n",
    "\n",
    "    # Why does this not work with RBF?\n",
    "\n",
    "    ### Training set\n",
    "\n",
    "    new_train_df = train_df.interpolate(method=\"akima\")\n",
    "    new_train_df = new_train_df.fillna(train_df.mean())\n",
    "\n",
    "    # Encode season data\n",
    "\n",
    "    binary_version_seasons = pd.get_dummies(new_train_df['season'])\n",
    "    new_train_df = new_train_df.drop(columns=['season']).join(binary_version_seasons)\n",
    "\n",
    "    y_train = new_train_df[\"price_CHF\"].to_numpy()\n",
    "    X_train = new_train_df.drop(columns=[\"price_CHF\"]).to_numpy()\n",
    "\n",
    "    ### Test set\n",
    "\n",
    "    new_test_df = test_df.interpolate(method=\"akima\")\n",
    "    new_test_df = new_test_df.fillna(new_test_df.mean())\n",
    "\n",
    "    # Encode season data\n",
    "\n",
    "    new_test_df = new_test_df.drop(columns=['season']).join(binary_version_seasons)\n",
    "\n",
    "    X_test = new_test_df.to_numpy()\n",
    "\n",
    "    # Use sklearn imputation\n",
    "\n",
    "    # new_df = train_df.fillna(train_df.mean())\n",
    "    # y_train = new_df[\"price_CHF\"].to_numpy()\n",
    "    # X_train = new_df.drop(columns=[\"price_CHF\"]).to_numpy()\n",
    "\n",
    "    # new_test_df = test_df.fillna(test_df.mean())\n",
    "    # X_test = new_test_df.to_numpy()\n",
    "\n",
    "    print(new_train_df.head())\n",
    "    print(new_test_df.head())\n",
    "\n",
    "\n",
    "\n",
    "    assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (\n",
    "                X_test.shape[0] == 100), \"Invalid data shape\"\n",
    "    return X_train, y_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_R2(y_pred, y):\n",
    "\n",
    "    R2 = r2_score(y, y_pred)\n",
    "\n",
    "    assert np.isscalar(R2)\n",
    "    return R2\n",
    "\n",
    "\n",
    "def calculate_RMSE(y_pred, y):\n",
    "    \"\"\"This function takes test data points (X and y), and computes the empirical RMSE of\n",
    "    predicting y from X using a linear model with weights w.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred: array of floats\n",
    "    y: array of floats, dim = (15,), input labels\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    RMSE: float: dim = 1, RMSE value\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine mean squared error\n",
    "    RMSE = mean_squared_error(y, y_pred) ** 0.5\n",
    "\n",
    "    assert np.isscalar(RMSE)\n",
    "    return RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling_and_prediction(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    This function defines the model, fits training data and then does the prediction with the test data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with 10 features\n",
    "    y_train: array of floats, training output\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with 10 features\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    y_test: array of floats: dim = (100,), predictions on test set\n",
    "    \"\"\"\n",
    "\n",
    "    # Create storage array for predicted y values\n",
    "    y_pred1 = np.zeros(X_test.shape[0])\n",
    "\n",
    "    # Leave out seasons data\n",
    "    # X_train = X_train[:, 1:]\n",
    "\n",
    "    # Define final test data\n",
    "    X_test1 = X_test\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    '''\n",
    "    gpr = GaussianProcessRegressor(kernel=DotProduct())\n",
    "    gpr.fit(X_train[:,1:], y_train)\n",
    "    '''\n",
    "\n",
    "    # Storage array for RMSE values\n",
    "    RMSE_mat = np.zeros(9)\n",
    "    R2_mat = np.zeros(9)\n",
    "\n",
    "    # Define n_fold cross validation\n",
    "    kf = KFold(9)\n",
    "    mat_i = 0\n",
    "\n",
    "    # Storage for all n_fold models\n",
    "    models = []\n",
    "\n",
    "    # Perform Cross validation\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_folds = X_train[train_index]\n",
    "        y_train_folds = y_train[train_index]\n",
    "\n",
    "        gpr = GaussianProcessRegressor(kernel=DotProduct())\n",
    "        gpr.fit(X_train_folds, y_train_folds)\n",
    "\n",
    "        X_test = X_train[test_index]\n",
    "        y_test = y_train[test_index]\n",
    "\n",
    "        y_pred, sigma = gpr.predict(X_test, return_std=True)\n",
    "\n",
    "        # print(sigma)\n",
    "\n",
    "        models.append(gpr)\n",
    "\n",
    "        RMSE_mat[mat_i] = calculate_RMSE(y_pred, y_test)\n",
    "        R2_mat[mat_i] = calculate_R2(y_pred, y_test)\n",
    "\n",
    "        mat_i = mat_i + 1\n",
    "\n",
    "    print(RMSE_mat)\n",
    "    print(R2_mat)\n",
    "\n",
    "    # Determine best model\n",
    "    best_index_RMSE = np.argmin(RMSE_mat)\n",
    "    best_index_R2 = np.argmin(R2_mat)\n",
    "\n",
    "    final_gpr_RMSE = models[best_index_RMSE]\n",
    "    final_gpr_R2 = models[best_index_R2]\n",
    "\n",
    "    # y_pred = final_gpr_RMSE.predict(X_test1[:, 1:])\n",
    "    y_pred = final_gpr_R2.predict(X_test1[:, :])\n",
    "\n",
    "\n",
    "    # print(gpr.score(X_train[:,1:], y_train))\n",
    "\n",
    "    '''\n",
    "    ps = PolynomialCountSketch(degree=3, random_state=1)\n",
    "    X_features = ps.fit_transform(X)\n",
    "    #print(np.exp(X_train[5,1]))\n",
    "    '''\n",
    "    # plt.plot(np.exp(X_train[:,1]),np.exp(y_train),'.')\n",
    "\n",
    "    assert y_pred.shape == (100,), \"Invalid data shape\"\n",
    "    return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
