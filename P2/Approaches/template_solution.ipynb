{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This serves as a template which will guide you through the implementation of this task.  It is advised\n",
    "# to first read the whole template and get a sense of the overall structure of the code\n",
    "# First, we import necessary libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, RBF, Matern, RationalQuadratic, ExpSineSquared\n",
    "from sklearn.kernel_approximation import PolynomialCountSketch\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    \"\"\"\n",
    "    This function loads the training and test data, preprocesses it, removes the NaN values and interpolates the missing\n",
    "    data using imputation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with features\n",
    "    y_train: array of floats, training output with labels\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with features\n",
    "    \"\"\"\n",
    "    # Load training data\n",
    "    train_df = pd.read_csv(\"/home/otps3141/Documents/Git Hub/IML-2023/P2/train.csv\")\n",
    "\n",
    "\n",
    "\n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(\"/home/otps3141/Documents/Git Hub/IML-2023/P2/test.csv\")\n",
    "\n",
    "\n",
    "\n",
    "    # Perform data preprocessing, imputation and extract X_train, y_train and X_test using mean values\n",
    "\n",
    "    # Use interpolation for missing values. Interpolate cannot handle missing starting or end values. So fill these up with mean()\n",
    "\n",
    "    # Why does this not work with RBF?\n",
    "\n",
    "    ### Training set\n",
    "\n",
    "    new_train_df = train_df.interpolate(method=\"akima\")\n",
    "    new_train_df = new_train_df.fillna(train_df.mean())\n",
    "\n",
    "\n",
    "    # Encode season data\n",
    "\n",
    "    binary_version_seasons = pd.get_dummies(new_train_df['season'])\n",
    "    new_train_df = new_train_df.drop(columns=['season']).join(binary_version_seasons)\n",
    "\n",
    "    ### Test set\n",
    "\n",
    "    new_test_df = test_df.interpolate(method=\"akima\")\n",
    "    new_test_df = new_test_df.fillna(new_test_df.mean())\n",
    "\n",
    "    # Encode season data\n",
    "\n",
    "    new_test_df = new_test_df.drop(columns=['season']).join(binary_version_seasons)\n",
    "\n",
    "    ###\n",
    "\n",
    "    seasons = train_df['season'].unique().tolist()\n",
    "\n",
    "    season_X_train = {}\n",
    "    season_y_train = {}\n",
    "    season_X_test = {}\n",
    "\n",
    "    for season in seasons:\n",
    "\n",
    "        season_X_train[f'{season}'] = new_train_df[new_train_df[f'{season}'] == 1].drop(columns=[\"price_CHF\"])\n",
    "        season_y_train[f'{season}'] = new_train_df[new_train_df[f'{season}'] == 1]['price_CHF']\n",
    "        season_X_test[f'{season}'] = new_test_df[new_test_df[f'{season}'] == 1]\n",
    "\n",
    "\n",
    "\n",
    "    # assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (\n",
    "    #             X_test.shape[0] == 100), \"Invalid data shape\"\n",
    "\n",
    "    return season_X_train, season_y_train, season_X_test, seasons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/otps3141/Documents/Git Hub/IML-2023/P2/train.csv\")\n",
    "\n",
    "test_df = pd.read_csv(\"/home/otps3141/Documents/Git Hub/IML-2023/P2/test.csv\")\n",
    "\n",
    "# seasonal_data_indexes = pd.DataFrame(test_df['season'])\n",
    "\n",
    "# seasonal_data_indexes\n",
    "\n",
    "# seasons = train_df['season'].unique().tolist()\n",
    "\n",
    "# season_split_data = {}\n",
    "# y_values_seasons = {}\n",
    "# test_season_split_data = {'seasonal_data': seasonal_data_indexes}\n",
    "\n",
    "# # Impute and split the data over the seasons.\n",
    "# temp = train_df.loc[train_df['season'] == 'winter']\n",
    "# temp_interpolid = temp.interpolate('akima').fillna(temp.mean())\n",
    "\n",
    "\n",
    "\n",
    "# # print(temp)\n",
    "# print(temp_interpolid)\n",
    "#     # season_split_data[season] = temp_interpolid.drop(columns=['price_CHF'], axis=1)\n",
    "#     # y_values_seasons[season] = temp_interpolid['price_CHF']\n",
    "\n",
    "#     # temp_test = test_df.loc[test_df['season'] == season]\n",
    "#     # temp_test_interpolid = temp_test.interpolate('akima').fillna(temp_test.mean())\n",
    "#     # test_season_split_data[season] = temp_test_interpolid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_574927/64763305.py:2: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  new_train_df = new_train_df.fillna(train_df.mean())\n",
      "/tmp/ipykernel_574927/64763305.py:13: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  new_test_df = new_test_df.fillna(new_test_df.mean())\n"
     ]
    }
   ],
   "source": [
    "new_train_df = train_df.interpolate(method=\"akima\")\n",
    "new_train_df = new_train_df.fillna(train_df.mean())\n",
    "\n",
    "\n",
    "# Encode season data\n",
    "\n",
    "binary_version_seasons = pd.get_dummies(new_train_df['season'])\n",
    "new_train_df = new_train_df.drop(columns=['season']).join(binary_version_seasons)\n",
    "\n",
    "### Test set\n",
    "\n",
    "new_test_df = test_df.interpolate(method=\"akima\")\n",
    "new_test_df = new_test_df.fillna(new_test_df.mean())\n",
    "\n",
    "# Encode season data\n",
    "\n",
    "new_test_df = new_test_df.drop(columns=['season']).join(binary_version_seasons)\n",
    "\n",
    "seasons = train_df['season'].unique().tolist()\n",
    "\n",
    "season_X_train = {}\n",
    "season_y_train = {}\n",
    "season_X_test = {}\n",
    "\n",
    "for season in seasons:\n",
    "\n",
    "    season_X_train[f'{season}'] = new_train_df[new_train_df[f'{season}'] == 1].drop(columns=[\"price_CHF\"])\n",
    "    season_y_train[f'{season}'] = new_train_df[new_train_df[f'{season}'] == 1]['price_CHF']\n",
    "    season_X_test[f'{season}'] = new_test_df[new_test_df[f'{season}'] == 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_R2(y_pred, y):\n",
    "\n",
    "    R2 = r2_score(y, y_pred)\n",
    "\n",
    "    assert np.isscalar(R2)\n",
    "    return R2\n",
    "\n",
    "\n",
    "def calculate_RMSE(y_pred, y):\n",
    "    \"\"\"This function takes test data points (X and y), and computes the empirical RMSE of\n",
    "    predicting y from X using a linear model with weights w.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred: array of floats\n",
    "    y: array of floats, dim = (15,), input labels\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    RMSE: float: dim = 1, RMSE value\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine mean squared error\n",
    "    RMSE = mean_squared_error(y, y_pred) ** 0.5\n",
    "\n",
    "    assert np.isscalar(RMSE)\n",
    "    return RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling_and_prediction(X_train, y_train, X_test, seasons):\n",
    "    \"\"\"\n",
    "    This function defines the model, fits training data and then does the prediction with the test data \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: matrix of floats, training input with 10 features\n",
    "    y_train: array of floats, training output\n",
    "    X_test: matrix of floats: dim = (100, ?), test input with 10 features\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    y_test: array of floats: dim = (100,), predictions on test set\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred=np.zeros(X_test['spring'].shape[0])\n",
    "    # y_pred = np.zeros(X_test['seasonal_data'].shape[0])\n",
    "    #TODO: Define the model and fit it using training data. Then, use test data to make predictions\n",
    "\n",
    "    # Define n_fold cross validation\n",
    "    kf = KFold(10)\n",
    "\n",
    "    # Define error\n",
    "    error_model = 'R2'\n",
    "\n",
    "    # Define model\n",
    "    model = GaussianProcessRegressor(kernel=DotProduct())\n",
    "\n",
    "\n",
    "    # Define storage for y prediction\n",
    "    y_pred_dict = {}\n",
    "\n",
    "    for season in seasons:\n",
    "        X_test_season = X_test[season].drop(columns=seasons)\n",
    "        X_train_season = X_train[season].drop(columns=seasons)\n",
    "        y_train_season = y_train[season]\n",
    "\n",
    "        y_pred_dict[season] = _fit_kfold(kf_splitter=kf, X_test=X_test_season, X_train=X_train_season,\n",
    "                                    y_train=y_train_season, error_method=error_model, model=model)\n",
    "\n",
    "        # indices = seasonal_data_indexes.index[seasonal_data_indexes['season'] == season].to_numpy()\n",
    "        # y_pred[indices] = y_pred_dict[season]\n",
    "\n",
    "    y_pred = y_pred_dict['spring']\n",
    "\n",
    "\n",
    "    assert y_pred.shape == (100,), \"Invalid data shape\"\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def modeling_and_prediction(X_train, y_train, X_test):\n",
    "#     \"\"\"\n",
    "#     This function defines the model, fits training data and then does the prediction with the test data\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     X_train: matrix of floats, training input with 10 features\n",
    "#     y_train: array of floats, training output\n",
    "#     X_test: matrix of floats: dim = (100, ?), test input with 10 features\n",
    "\n",
    "#     Returns\n",
    "#     ----------\n",
    "#     y_test: array of floats: dim = (100,), predictions on test set\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Create storage array for predicted y values\n",
    "#     y_pred1 = np.zeros(X_test.shape[0])\n",
    "\n",
    "#     # Leave out seasons data\n",
    "#     # X_train = X_train[:, 1:]\n",
    "\n",
    "#     # Define final test data\n",
    "#     X_test1 = X_test\n",
    "\n",
    "#     X_train = np.array(X_train)\n",
    "#     y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "#     # Storage array for RMSE values\n",
    "#     RMSE_mat = np.zeros(9)\n",
    "#     R2_mat = np.zeros(9)\n",
    "\n",
    "#     # Define n_fold cross validation\n",
    "#     kf = KFold(9)\n",
    "#     mat_i = 0\n",
    "\n",
    "#     # Storage for all n_fold models\n",
    "#     models = []\n",
    "\n",
    "#     # Perform Cross validation\n",
    "#     for train_index, test_index in kf.split(X_train):\n",
    "#         X_train_folds = X_train[train_index]\n",
    "#         y_train_folds = y_train[train_index]\n",
    "\n",
    "#         gpr = GaussianProcessRegressor(kernel=DotProduct())\n",
    "#         gpr.fit(X_train_folds, y_train_folds)\n",
    "\n",
    "#         X_test = X_train[test_index]\n",
    "#         y_test = y_train[test_index]\n",
    "\n",
    "#         y_pred, sigma = gpr.predict(X_test, return_std=True)\n",
    "\n",
    "#         # print(sigma)\n",
    "\n",
    "#         models.append(gpr)\n",
    "\n",
    "#         RMSE_mat[mat_i] = calculate_RMSE(y_pred, y_test)\n",
    "#         R2_mat[mat_i] = calculate_R2(y_pred, y_test)\n",
    "\n",
    "#         mat_i = mat_i + 1\n",
    "\n",
    "#     # print(RMSE_mat)\n",
    "#     # print(R2_mat)\n",
    "\n",
    "#     # Determine best model\n",
    "#     best_index_RMSE = np.argmin(RMSE_mat)\n",
    "#     best_index_R2 = np.argmin(R2_mat)\n",
    "\n",
    "#     final_gpr_RMSE = models[best_index_RMSE]\n",
    "#     final_gpr_R2 = models[best_index_R2]\n",
    "\n",
    "#     # y_pred = final_gpr_RMSE.predict(X_test1[:, 1:])\n",
    "#     y_pred = final_gpr_R2.predict(X_test1[:, :])\n",
    "\n",
    "\n",
    "#     # print(gpr.score(X_train[:,1:], y_train))\n",
    "\n",
    "#     '''\n",
    "#     ps = PolynomialCountSketch(degree=3, random_state=1)\n",
    "#     X_features = ps.fit_transform(X)\n",
    "#     #print(np.exp(X_train[5,1]))\n",
    "#     '''\n",
    "#     # plt.plot(np.exp(X_train[:,1]),np.exp(y_train),'.')\n",
    "\n",
    "#     assert y_pred.shape == (100,), \"Invalid data shape\"\n",
    "#     return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_kfold(kf_splitter, X_test, X_train, y_train, model, error_method):\n",
    "    \"\"\"\"\n",
    "    Helper function to compute the KFolds and keep the rest of the modeling function cleaner.\n",
    "    The model is the machine learning model that fits the data.\n",
    "    \"\"\"\n",
    "    # Storage for errors\n",
    "    error_matrix = np.zeros(kf_splitter.get_n_splits())\n",
    "\n",
    "    # Storage for all n_fold models\n",
    "    models = []\n",
    "\n",
    "    # Perform Cross validation\n",
    "    for i, (train_index, test_index) in enumerate(kf_splitter.split(X_train)):\n",
    "        X_train_folds = X_train[train_index]\n",
    "        y_train_folds = y_train[train_index]\n",
    "\n",
    "        X_test_folds = X_train[test_index]\n",
    "        y_test_folds = y_train[test_index]\n",
    "\n",
    "        # The model is refitted every time.\n",
    "        model.fit(X_train_folds, y_train_folds)\n",
    "        y_pred_folds, sigma = model.predict(X_test_folds, return_std=True)\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "        if error_method == 'RMSE':\n",
    "            error_matrix[i] = calculate_RMSE(y_pred_folds, y_test_folds)\n",
    "\n",
    "        elif error_method == 'R2':\n",
    "            error_matrix[i] = calculate_R2(y_pred_folds, y_test_folds)\n",
    "\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "\n",
    "    best_index = np.argmin(error_matrix)\n",
    "    best_fit = models[best_index]\n",
    "\n",
    "    y_pred = best_fit.predict(X_test)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_574927/2588899548.py:33: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  new_train_df = new_train_df.fillna(train_df.mean())\n",
      "/tmp/ipykernel_574927/2588899548.py:44: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  new_test_df = new_test_df.fillna(new_test_df.mean())\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([ 23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\\n            ...\\n            215, 216, 217, 218, 219, 220, 221, 222, 223, 224],\\n           dtype='int64', length=202)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m X_train, y_train, X_test, seasons \u001b[39m=\u001b[39m data_loading()\n\u001b[1;32m      3\u001b[0m \u001b[39m# The function retrieving optimal LR parameters\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m y_pred \u001b[39m=\u001b[39m modeling_and_prediction(X_train, y_train, X_test, seasons)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Save results in the required format\u001b[39;00m\n\u001b[1;32m      7\u001b[0m dt \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(y_pred)\n",
      "Cell \u001b[0;32mIn[93], line 38\u001b[0m, in \u001b[0;36mmodeling_and_prediction\u001b[0;34m(X_train, y_train, X_test, seasons)\u001b[0m\n\u001b[1;32m     35\u001b[0m     X_train_season \u001b[39m=\u001b[39m X_train[season]\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39mseasons)\n\u001b[1;32m     36\u001b[0m     y_train_season \u001b[39m=\u001b[39m y_train[season]\n\u001b[0;32m---> 38\u001b[0m     y_pred_dict[season] \u001b[39m=\u001b[39m _fit_kfold(kf_splitter\u001b[39m=\u001b[39;49mkf, X_test\u001b[39m=\u001b[39;49mX_test_season, X_train\u001b[39m=\u001b[39;49mX_train_season,\n\u001b[1;32m     39\u001b[0m                                 y_train\u001b[39m=\u001b[39;49my_train_season, error_method\u001b[39m=\u001b[39;49merror_model, model\u001b[39m=\u001b[39;49mmodel)\n\u001b[1;32m     41\u001b[0m     \u001b[39m# indices = seasonal_data_indexes.index[seasonal_data_indexes['season'] == season].to_numpy()\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[39m# y_pred[indices] = y_pred_dict[season]\u001b[39;00m\n\u001b[1;32m     44\u001b[0m y_pred \u001b[39m=\u001b[39m y_pred_dict[\u001b[39m'\u001b[39m\u001b[39mspring\u001b[39m\u001b[39m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[91], line 14\u001b[0m, in \u001b[0;36m_fit_kfold\u001b[0;34m(kf_splitter, X_test, X_train, y_train, model, error_method)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# Perform Cross validation\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i, (train_index, test_index) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(kf_splitter\u001b[39m.\u001b[39msplit(X_train)):\n\u001b[0;32m---> 14\u001b[0m     X_train_folds \u001b[39m=\u001b[39m X_train[train_index]\n\u001b[1;32m     15\u001b[0m     y_train_folds \u001b[39m=\u001b[39m y_train[train_index]\n\u001b[1;32m     17\u001b[0m     X_test_folds \u001b[39m=\u001b[39m X_train[test_index]\n",
      "File \u001b[0;32m/usr/lib64/python3.11/site-packages/pandas/core/frame.py:3811\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3810\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3811\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3813\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib64/python3.11/site-packages/pandas/core/indexes/base.py:6113\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6111\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6113\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6115\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6117\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.11/site-packages/pandas/core/indexes/base.py:6173\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6171\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6172\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 6173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6175\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   6176\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([ 23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\\n            ...\\n            215, 216, 217, 218, 219, 220, 221, 222, 223, 224],\\n           dtype='int64', length=202)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Data load\n",
    "X_train, y_train, X_test, seasons = data_loading()\n",
    "# The function retrieving optimal LR parameters\n",
    "y_pred = modeling_and_prediction(X_train, y_train, X_test, seasons)\n",
    "# Save results in the required format\n",
    "\n",
    "dt = pd.DataFrame(y_pred)\n",
    "\n",
    "dt.columns = ['price_CHF']\n",
    "dt.to_csv('/home/otps3141/Documents/Git Hub/IML-2023/P2/results.csv', index=False)\n",
    "print(\"\\nResults file successfully generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
